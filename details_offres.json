[
    {
        "title": "Senior Analytics Engineer H/F",
        "entreprise": "PayFit",
        "localisation": "Paris 8e - 75",
        "contrat": "CDI",
        "description": "Get to know us\n\nDo you want to help us shape what the future of work will look like and how IT will best embrace our life's aspirations? If this sounds like a journey you want to embark on, we may have the right role for you !PayFit is an intuitive cloud-based payroll and employee management solution designed specifically for SMBs. Since 2015, we have set ourselves a mission to simplify payroll for SMBs and enable employers and employees to grow together. We are a European company operating from 3 main countries (France, Spain, and the UK) where we are supporting over 18,000 clients.\n\nCreating a fulfilling work environment and culture is also a core mission at PayFit, and our day-to-day work philosophy is reflected in our four values :\n\nCare : We genuinely care for others whoever they are, whatever they think.\n\nExcellence : We aim to improve and achieve better results every day.\n\nHumility : Staying humble and exchanging transparent feedback helps us to grow and improve.\n\nPassion : We are the architects of PayFit's success.\n\nA key part of our culture, and essential for our success, is also improving the diversity of our teams and building an inclusive culture where you can BE yourself at work.\n\nThis is why our recruitment focuses on the skills you demonstrate, and not only on your academic background or previous professional experiences. At PayFit we understand that you can gain applicable skills through a variety of life experiences and we are interested in knowing them, too.\n\nLocation :\nThe position is based in France and Spain.\n\nYour missions :\n\nGet onboard of the PayFit rocket by joining our Data Team as a Analytics Engineer. You will :\n- Take care of the maintenance, evolution, and optimisation of PayFit datawarehouse\n- Perform technical and functional tests of the data\n- Document the data documentation\n- Deploy new SQL models in Production\n- Ensure the data safety and security in the datawarehouse to BE compliant with the GDPR and the ISO 27001\n- Manage all the layers of the datawarehouse, you will have a strong partnership to help the Data Engineering team building the best staging layer as possible\n- BE the center of excellence and the best technical buddy of the Data Analyst Team and the OPS Teams\n- Maintain the semantic layer part\n\nThis job has been tailored for you if :\n- You have at least 5+ years of experience as a Data Player (Engineer / Analyst / Scientist)\n- You speak SQL better than your mother tongue\n- You have already made datawarehouse modelization\n- You like making small Python script to help you in your daily working life\n- You want to work in an international environment\n\nIf you think you would BE a good fit even if you don't meet 100% of the requirements, we would love to hear from you !\n\nYour future team :\n\nAt the Data Tribe at PayFit (15 people), we are currently improving our cloud-based data platform to unlock the full potential of our data, bringing the platform to the next level to empower self-service analytics at a high pace on a strong foundational base, with tools that are currently top tier in the data ecosystem (Airbyte, Airflow, Snowflake).\n\nThe analytics engineer team is composed of 5 people inside a 15 people data team. The team is based in France and Spain.\n\nHiring process :\n\n1. Initial Discovery Call : A Talent Acquisition representative will assess your qualifications and fit for the role - 30 min\n2. Technical interview with the team (2 Analytics Engineers) - 60min\n3. Interview with Olivier (Lead of Data team) - 60min\n\nBackground Check (ISO27001 certification) : identity, diploma, and past professional experiences will BE checked after the offer.\n\nWhat we offer\n\nFlexibility : We believe IT is key to produce your best work and to BE fulfilled. We therefore offer the possibility to work away from our main offices, within France/UK/Spain; as well as abroad for a defined period. Further requirements may apply depending on the role and your overall experience.\nLearning & Development : In PayFit we have a great learning platform where you can learn new skills every day with the support of our company. We also have English language courses to improve your business communication vocabulary and get to the next level.\nCareer Development : We want you to progress and BE free to choose which direction you want to grow. There are also opportunities for internal moves.\nHealth promotion : A Gym at our Paris office and a GymLib subscription with preferential rates. 4 paid sessions with a mental health practitioner and online support with Moka.Care.\nHealth insurance : Mutuelle Henner (60% covered by PayFit).\nTransportation : 50% covered for your public transportation card for those living within Ile de France. A budget to travel to the office for those who live outside of IT.\nMeals : A restaurant card with our partner Swile (9€ per workday).\nhome office budget : 150€ per year to help you get set up in the best conditions. A MacBook is our standard working tool.\nParental support : 20 weeks maternity leave covered by PayFit and 4 weeks leave for the second parent.\nTime off : 25 days of holidays + RTT days (depending on the contract).\n\nDisability Inclusion : All of our positions are open to any person living with a disability. To guarantee equal treatment and opportunities, we will take, based on individual needs, appropriate measures to adapt the work conditions of PayFiters with disabilities, and if needed also during the recruitment process. Please let us know what you need and we will do our best to accommodate !",
        "link": "https://www.hellowork.com/fr-fr/emplois/60257918.html"
    },
    {
        "title": "Senior Analytics Engineer H/F",
        "entreprise": "Shippeo",
        "localisation": "Paris 10e - 75",
        "contrat": "CDI",
        "description": "Our vision is to become the leading data platform for the freight industry. By harnessing our growing network, real-time data, and AI, we aim to help supply chains deliver exceptional customer service and achieve operational excellence.\n\nYour mission\n\nAs a senior data analyst, you will drive major analytics initiatives with autonomy and vision. You'll transform raw data into actionable insights, empowering teams across the organization. With your expertise in data storytelling, you'll BE the go-to person for creating impactful visualizations and presenting findings that shape strategic decisions.\n\nWhat you'll do\n- Data mastery :\n- Uncover complex relationships within datasets and reveal insights that others might miss\n- Design and manipulate large datasets to build actionable and insightful reports that align with business needs\n- Create elegant, on-trend visualizations that simplify complex data, making IT accessible to technical and non-technical stakeholders alike\n- Strategic impact :\n- Lead analytics projects critical to business success, ensuring seamless communication and collaboration across teams\n- Develop production-ready code for large-scale projects, maintaining best practices in documentation and quality\n- Mentor junior analysts, elevating their technical and analytical skills\n- Cross-functional leadership :\n- Act as a trusted advisor by engaging with stakeholders to understand their needs and expectations\n- Keep teams informed and aligned on progress, timelines, and changes with clear and proactive communication\n- Foster innovation by creating opportunities for the team to grow and thrive, all while ensuring top-notch results\n\nYour profile\n- Must-haves :\n- MSc degree (or equivalent) in Data Science, Applied Mathematics, Statistics, or a related field\n- 4+ years of hands-on experience in building and deploying data products in an Agile environment.\n- Strong proficiency in SQL and relational databases.\n- Strong experience in cloud data warehouse (ideally Snowflake)\n- Expertise in a data visualization tool like Tableau or Looker\n- Solid experience with data preparation scripts and creating data marts\n- Skills on DBT\n- Knowledge of algorithms, data structures, and version control (Git)\n- Bonus points :\n- Familiarity with cloud platforms (GCP or AWS)\n- Python proficiency and an understanding of programming best practices",
        "link": "https://www.hellowork.com/fr-fr/emplois/59735948.html"
    },
    {
        "title": "Ingénieur - Ingénieure Big Data Palantir H/F",
        "entreprise": "SIBYL",
        "localisation": "Paris 9e - 75",
        "contrat": "CDI",
        "description": "Sibyl - Impact driven & Bias to action\n\nSibyl est une entreprise de services professionnels de premier plan, offrant un accompagnement end-to-end pour les principales plateformes commerciales développées par Palantir : Foundry et AIP.\nAvec plus de 10 ans d'expertise dans le déploiement sur le terrain, nous collaborons étroitement avec Palantir pour mener à bien des déploiements impactants. De l'assistance aux centres d'excellence clients à la conception de nouveaux cas d'usage, en passant par l'analyse coût-bénéfice des cas d'usage en GenAI, notre approche est centrée sur l'impact.\nMissions principales\nEn tant qu'ingénrieu déployé, vous serez au coeur de l'action pour transformer les défis opérationnels de nos clients en solutions concrètes et basées sur les données.\nVous aurez pour mission de structurer des problématiques complexes, comprendre les besoins des utilisateurs et intégrer des solutions Palantir pour délivrer des résultats mesurables.\n\nVos responsabilités incluront :\nTravailler directement avec des experts terrain (data scientists, ingénieurs, analystes) pour identifier les enjeux clés\nIdentifier et structurer des jeux de données pertinents\nConcevoir et intégrer des pipelines de données stables et extensibles\nAccompagner les utilisateurs dans la mise en place de workflows personnalisés\nAnimer des sessions de formation pour assurer l'adoption des solutions Palantir\nPrésenter les résultats des déploiements à des audiences variées (analystes, directions)\nDémontrer les capacités de nos solutions à de nouveaux prospects\nExplorer et définir des opportunités dans de nouveaux secteurs d'activité\n\nProfil recherché\nAnglais billingue (Francais optionnel)\nDiplôme d'ingénieur grande école (X, ponts et chaussées, central Paris)\nExpérience significative avec Palantir Foundry et/ou AIP (exigée)\nExcellente capacité d'analyse et de synthèse\nGoût pour l'exploration des problématiques complexes et la recherche de solutions innovantes\nCapacité à naviguer dans des environnements incertains et non structurés\nHumilité et approche collaborative : l'impact compte plus que la reconnaissance individuelle\nAdaptabilité et volonté d'apprendre\n\nConditions et avantages\nPoste basé à Paris\nMobilité requise : 75% (déplacements possibles en France et à l'international)\n(Bonus) Maîtrise du français",
        "link": "https://www.hellowork.com/fr-fr/emplois/61979166.html"
    },
    {
        "title": "Expert Big Data H/F",
        "entreprise": "CGI",
        "localisation": "Paris - 75",
        "contrat": "CDI",
        "description": "Expert(e) Big Data F/H\n\nDescription de poste\nBig Data, Data Science, Data analyse, Data architecture... Ça n'a pas de secret pour vous ?\nQue vous commenciez votre carrière professionnelle ou que vous soyez spécialiste de l'une de ces disciplines, intégrer notre communauté Data, c'est l'assurance de progresser, innover, partager, vous certifier et rendre service à nos clients.\n\nRejoignez notre centre d'excellence en innovation à Paris et rendez unique l'expérience digitale de nos clients en travaillant sur des sujets tels que le marketing digital, User eXperience, CRM, RPA, data, développement web et mobile, API management ou encore cybersécurité.\n\nFonctions et responsabilités\nVous êtes passionné par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d'applications data science, modélisation de base de données...\n\nVous disposez de connaissances sur un ou plusieurs outils Big Data (Hadoop, Spark, Hive, Kafka, nifi...) et/ou NoSQL (MongoDB, Neo4j, Cassandra...) et vous maitrisez un des trois langages suivants : Java, Scala, Python.\n\nVous souhaitez diversifier vos compétences Big Data pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l'innovation ? Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d'autres outils Big Data que ceux de votre domaine de compétences initial.\n\nEn tant que Data Engineer, vous serez intégré.e à un pôle de consultants.es spécialistes du Big Data intervenants sur des projets stimulants.\n\nVos missions seront :\n- Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place\n- Travailler en collaboration avec les ingénieurs techniques et autres experts.es afin de rechercher et fournir des réponses aux problématiques techniques\n- Réaliser les travaux d'implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies...)\n- Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DEVOPS, Git, CI/CD...)\n- Participer à l'élaboration et la révision de normes / documentation technique\n- Animer des formations internes. Accompagner la montée en compétences des équipes\n- Assurer un support technique Big Data aux équipes et aux clients au quotidien\n\nFort d'une intégration réussie, de nombreuses possibilités d'évolutions de carrière s'offriront rapidement à vous, dans l'animation de la filière technique ou dans le consulting de solutions Data.\n\nEn rejoignant CGI, vous bénéficiez notamment d'une offre complète de formations (techniques, métiers, développement personnel...), de flexibilité grâce à notre accord télétravail (jusqu'à 3 jours de télétravail par semaine), d'une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade...) et d'un package d'avantages intéressant (régime d'achats d'actions, participation, CSE...).\n\nQualités requises pour réussir dans ce rôle\n- Passionné d'informatique et de données, vous aimez le travail en équipe, apprendre et partager.\n- Vous êtes également doté d'un esprit audacieux et ambitieux.\n- Vous faites preuve d'initiative et travaillez sur le long terme.\n- Vous justifiez de 2 à 5 ans d'expérience professionnelle au sein d'une entreprise de services numériques ou d'un cabinet de conseil dans le Domaine du Big Data.\n- Vous disposez d'une vision large des technologies et vous maîtrisez au moins une technologie Big Data.\n\nCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l'évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d'accessibilité et de clarté, le point médian n'est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.\n\nEnsemble, en tant que propriétaires, mettons notre savoir-faire à l'oeuvre.\n\nLa vie chez CGI est ancrée dans l'actionnariat, le travail d'équipe, le respect et un sentiment d'appartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que...\n\nNous vous invitons à devenir propriétaire dès le jour 1 alors que nous travaillons ensemble à faire de notre rêve une réalité. C'est pourquoi nous nous désignons comme associés de CGI, plutôt que comme employés. Nous tirons profit des retombées de notre succès collectif et contribuons activement à l'orientation et à la stratégie de notre entreprise.\n\nVotre travail crée de la valeur. Vous élaborerez des solutions novatrices et développerez des relations durables avec vos collègues et clients, tout en ayant accès à des capacités mondiales pour concrétiser vos idées, saisir de nouvelles opportunités, et bénéficier d'une expertise sectorielle et technologique de pointe.\n\nVous ferez évoluer votre carrière en vous joignant à une entreprise bâtie pour croître et durer. Vous serez soutenus par des leaders qui ont votre santé et bien-être à coeur et qui vous permettront de saisir des occasions afin de parfaire vos compétences et élargir les horizons.\n\nJoignez-vous à nous, l'une des plus importantes entreprises de conseil en technologie de l'information (TI) et en management au monde.",
        "link": "https://www.hellowork.com/fr-fr/emplois/60655692.html"
    },
    {
        "title": "Analytics Engineer H/F",
        "entreprise": "Younited Credit",
        "localisation": "Paris 9e - 75",
        "contrat": "CDI",
        "description": "Contexte\n\nEn tant que Senior Analytics Engineer, tu rejoindras la team Data Engineering, l'équipe la plus transverse de tout Younited, en contact avec l'ensemble des métiers et en charge d'imaginer la meilleure base data sans que tout s'écroule !\n\nTes responsabilités :\n- Concevoir, mettre en oeuvre, maintenir, documenter et promouvoir des produits de données robustes et pertinents (entrepôts, marts, exportations et tableaux de bord).\n- Développer, optimiser et maintenir les pipelines ETL.\n- Assister l'équipe commerciale dans le développement de leurs produits de données.\n- Encadrer les utilisateurs de Younited, en les aidant à exploiter efficacement les produits de données et en favorisant leur indépendance dans les tâches liées aux données.",
        "link": "https://www.hellowork.com/fr-fr/emplois/60681291.html"
    },
    {
        "title": "Senior Backend Engineer Craftman et Appétence Data Spécialiste en Big Data Paris ou Remote Partiel H/F",
        "entreprise": "Octopus IT",
        "localisation": "Paris - 75",
        "contrat": "CDI",
        "description": "Ils proposent deux activités distinctes : le service de conseil aux entreprises d'une part et la Startup Factory d'autre part.\n\nLa Startup Factory c'est : des idées/projets provenant directement des collaborateurs qui sont développés et auxquelles chacun contribue entre 2 et 4 jours/mois.\n\nSur ces deux activités, il y a deux moteurs principaux :\n- La culture de l'excellence, de simplicité et d'une quête de perfectionnement continue grâce notamment à des sessions d'entrainement et de partages de connaissances.\n- La data et l'IA, qui permettent d'atteindre un niveau de valeur ajoutée supérieur\n\nLa base de leur méthodologique est constituée principalement de TDD, BDD, pair programming et autres principes établis de qualité tirés notamment des pratiques prônées par Extreme Programming ou du Craftsmanship Manifesto.\n\nUne de leurs forces est leur formation interne (avec des profils de seniors ou d'architectes) et externe (avec des partenaires pour passer des certifications).\n\nChez eux, le collaborateur est placé au centre des préoccupations, permettant ainsi de créer une cohésion et une véritable culture au sein de l'entreprise. Par exemple, la majorité des projets se font en équipe et non seul. Vous vous entraînerez avec des coéquipiers à votre image dans un cadre agile (souvent Scrum).\n\nPour poursuivre leur croissance, répondre à leurs ambitions et développer de nouveaux marchés, nous recherchons plusieurs profils pour renforcer leurs effectifs.\n\nLe poste\n\nEn les rejoignant, vous travaillerez sur les problématiques suivantes :\n- Développer de nouvelles API et de nouvelles features\n- Robustesse, Volumétrie, Performance et Scalabilité\n- Améliorer la stack technique dans l'optique de scaler (factorisation, modernisation)\n- Réfléchir avec les équipes produits aux features à venir\n- Mise en place de méthodologie Craft pour assurer la performance du code : TDD, BDD\n- Optimiser la stack technique actuelle\n\nLa stack sur laquelle vous serez amené à travailler :\n- Langages de programmation suivants : Python, Java\n- Outils d'industrialisation : Gitlab, Jenkins\n- Infrastructure et déploiement : Docker / Kubernetes, Terraform\n- Travail en équipe : Git\n- Cloud : AWS / GCP / Azure\n- BDD : PostgreSql, MongoDB\n\nVotre profil\n- À partir de 5 ans d'expérience en CDI\n- Vous avez une expérience significative sur des problématiques Backend, notamment en Python et en Java\n- Vous vous sentez concerné·e par le Software Craftsmanship et faites de la veille technologique\n- Vous avez développé sur différent framework comme Flask ou Django\n- Vous aimez travailler en équipe et partager vos connaissances\n- Vous êtes ouvert·e aux autres et acceptez leurs points de vue avec bienveillance\n- Vous avez une appétence et l'envie d'évoluer dans des projets et des compétences orientées data\n\nLe salaire & avantages\n- 55-70 K€ selon expérience\n- RTT\n- Carte Swile & Mutuelle\n- 2/3 jours de télétravail par semaine\n\nEt plus encore...\n\nCe qu'on préfère\n- Être impliqué à fond dans une aventure avec de nombreux challenges techniques\n- Participation à des conférences sur les sujets Tech et Data\n- Très bonne ambiance, équipe solidaire et orientée partage d'informations\n- Beaucoup de workshops en interne et catalogue de formations à votre guise\n\nCe poste a été soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d'Experts en Recrutement Tech (CDI et clients finaux uniquement) - Visitez nous pour plus d'opportunités : www.octopusit.fr",
        "link": "https://www.hellowork.com/fr-fr/emplois/57414073.html"
    },
    {
        "title": "Date Engineer Python Pandas - SQL Scale Up Medtech Remote Flexible H/F",
        "entreprise": "Octopus IT",
        "localisation": "Paris - 75",
        "contrat": "CDI",
        "description": "Elle a lancé la première plateforme collaborative de prévention 100% dédiée à la santé au travail.\n\nLeur but ? Simplifier un maximum un secteur en train de devenir obsolète : la médecine du travail.\n\nLa solution comprend notamment une pré-visite sur tablette réalisée avant l'échange avec l'infirmière ou le médecin du travail, un dossier médical repensé, une plateforme de statistiques et des systèmes d'échanges digitaux avec les employeurs et les salariés.\n\nAyant levée 80 millions en début d'année, l'entreprise compte aujourd'hui 150 personnes dont 100 personnes à la tech. L'équilibre est prévue pour l'année prochaine !\n\nPlus de 2 millions de salariés sont suivis par des services de santé au travail qui ont déjà choisi la plateforme ! En fin d'année cela sera presque 4 millions !\n\nLe poste\n\nAu sein d'une équipe d'une quinzaine de personnes, tu seras amené à :\n- Tu rejoins l'équipe de data-engineering qui s'occupe de gérer les systèmes qui transfèrent de la donnée médicale : problématiques de base de données & de performance à prévoir !\n- Cette équipe est également en charge de certaines fonctionnalité techniques donc tu es appelé à apprendre à développer en JavaScript.\n- Tu es amené à travailler avec les autres équipes de développement et avec les responsables opérationnels\n- Tu participes aux activités communes de l'équipe et à l'amélioration continue : reviewer les PRs des collègues, améliorer la méthodologie de développement, amélioration de performance et de qualité (performance des applications, qualité de la code-base, qualité de la donnée etc.)\n- Environ 300 types de données différentes à aller récupérer et interpréter\n- Optimiser et automatiser les process et les différents flux data.\n\nLa stack actuelle\n- Data : Python (pandas)\n- Backend : Node.Js\n- Frontend : Angular\n- Infra : Kubernetes, Elastic Search\n- Azure, AWS\n- Base de données : PostgreSQL\n\nVotre profil\n- Diplômé d'une école d'ingénieur ou d'informatique\n- Entre 1 an et 5 an d'expérience sur des problématique Python et JS\n- Vous maîtrisez les langages Python et SQL et êtes ouvert pour monter en compétences sur d'autres langages comme le JS.\n- Passionné par le produit\n\nLe salaire & avantages\n- De 44K à 55K\n- Carte Swile & Mutuelle\n- 2 jours de télétravail par semaine\n- Incentives organisés par la direction (voyages...)\n\nEt plus encore...\n\nCe qu'on préfère\n- Être impliqué à fond dans une aventure avec de nombreux challenges techniques\n- Travailler sur un produit extrêmement large\n- Une équipe jeune, en pleine croissance et très soudée\n\nCe poste a été soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d'Experts en Recrutement Tech (CDI et clients finaux uniquement) - Visitez nous pour plus d'opportunités : www.octopusit.fr",
        "link": "https://www.hellowork.com/fr-fr/emplois/57414253.html"
    },
    {
        "title": "Senior Analytics Engineer H/F",
        "entreprise": "Mirakl",
        "localisation": "Paris - 75",
        "contrat": "CDI",
        "description": "Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l'ergonomie...\n\nElles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l'ensemble des produits.\n\nToutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au coeur de notre philosophie.\n\nEt pour favoriser ce partage avec d'autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\n\nA propos du job\n\nEn tant que Senior Analytics Engineer, vous jouerez un rôle clé dans la construction et l'optimisation des modèles de données, des pipelines et des solutions afin de favoriser la prise de décisions basée sur les données dans toute l'organisation.\nEn travaillant sur notre Data Platform, vous ferez le lien entre la Data Engineer et Data Analyst en fournissant des solutions évolutives, maintenables et performantes.\n\nAu quotidien, vous allez :\n- Concevoir, implémenter et maintenir des pipelines ETL/ELT robustes sur Databricks, en garantissant la fiabilité, la scalabilité et les performances des données.\n- Développer et optimiser du code SQL et Python pour transformer des données brutes en ensembles de données propres et réutilisables pour l'analyse et le reporting.\n- Construire et maintenir des tableaux de bord Superset pour fournir des insights exploitables aux différents stakeholders.\n- Contribuer au développement de modèles de données et maintenir une source unique de vérité dans l'organisation.\n- Collaborer étroitement avec les Data Analysts, Data Engineers et les équipes produit pour aligner les priorités et capacités.\n- Utiliser Scala si nécessaire pour des transformations et traitements avancés des données entre les couches Silver et Gold.\n- Assurer la qualité et la gouvernance des données en mettant en oeuvre les meilleures pratiques de test, de documentation et de monitoring.\n\nVous aimerez ce job si :\n- Vous avez un minimum 6 années d'expérience en tant que Data/Analytics Engineer ou dans un rôle similaire.\n- Vous maîtrisez SQL et Python, avec de l'expérience dans la conception et l'optimisation de requêtes et scripts complexes.\n- Vous avez une expérience pratique avec Databricks/AWS ou des plateformes de données similaires.\n- Vous avez de l'expérience dans la création de tableaux de bord sur Superset ou des outils BI similaires.\n- Vous connaissez dbt et les pratiques modernes de modélisation des données.\n- Vous avez de solides compétences en résolution de problèmes, attention aux détails et capacité à travailler dans un environnement dynamique.\n- Vous avez de bonnes compétences en communication pour collaborer avec des parties prenantes techniques ou non.\n\nLe petit +\n- Expérience préalable avec Scala.\n\nCe que nous proposons :\n- L'opportunité de travailler avec des technologies récentes.\n- Un environnement d'équipe collaboratif, innovant et bienveillant.\n- Des opportunités de développement professionnel et un accès à des formations avancées.\n- La chance d'avoir un impact significatif au sein d'une organisation data driven.\n\nEnvie de nous rejoindre ?\n- Un appel téléphonique de 30 minutes avec l'un de nos recruteurs Tech. Ce sera l'occasion de discuter de votre parcours, de vos attentes et de découvrir ce que Mirakl peut vous offrir.\n- Un cas pratique à faire chez vous\n- Un entretien technique d'1H via Zoom avec un membre de l'équipe Data, pour débriefer du cas pratique et explorer concrètement votre expertise et comment vos compétences peuvent contribuer à nos projets.\n- 2 entretiens de 45 minutes via Zoom avec vos futurs collègues chez Mirakl pour discuter de nos valeurs et de notre culture d'entreprise.\n\nMirakl est engagée en faveur de la diversité, de l'égalité des chances et de l'inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d'innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.",
        "link": "https://www.hellowork.com/fr-fr/emplois/60609605.html"
    },
    {
        "title": "Mid Analytics Engineer All Genders H/F",
        "entreprise": "Dailymotion",
        "localisation": "Paris - 75",
        "contrat": "CDI",
        "description": "Dailymotion is seeking an Analytics Engineer to join the Data Engineering Teams. Our craft is responsible for most of the Data products at Dailymotion; your work will have an impact throughout Dailymotion's business and help make data-driven decisions on products and strategy.\n\nYou'll join the Data Engineering craft at Dailymotion, to create and maintain data products. The Analytics Engineering team focuses on providing reliable data for analysis company-wide. This includes building and managing our multi-petabyte data warehouse, highly scalable client-facing analytics, data ingestion & distribution, and data synchronization systems. As an Analytics Engineer, you'll blend software engineering and data skills to maintain code and model data effectively. If you're eager to solve challenging business problems, this role offers a broad impact across all of Dailymotion's businesses.\n\nOur stack runs almost exclusively on Google Cloud Platform. You will work in an environment made up of Data Lakes (BigQuery, etc.), orchestration and scheduling platforms (Airflow), container-oriented deployment, and management platforms (Docker, K8S, JenkinsX), SQL, Data Quality Tools (DBT, Sifflet). You will also participate in data modeling activities and design of data flows until their implementation and support in production.\n- Expose the data through various means such as datamarts, and flat files for both internal and external users.\n- Build complex and efficient SQL queries to transform data within our data lake into reliable business entities and reporting aggregates. Identify and manage dependencies for these transformations, scheduling them using tools like Airflow.\n- Investigate discrepancies and quality issues in the data, as well as addressing performance issues.\n- Design optimized and cost-efficient data models in BQ while addressing business use cases.\n- Ensure data cleanliness, consistency, and availability by performing data quality checks and implementing monitoring.\n- Catalog and document various aspects of the data, including business entities, datamarts, dimensions, metrics, and business rules.\n- Serve as a subject matter expert on business entities and datamarts, providing training to users on SQL and analytics best practices (collaboration with Business Insight).\n- Innovate by proposing new tools, processes, documentation, and exploring emerging technologies during designated cool-down periods.\n\n- Minimum of 2-3 years of experience in Data Analytics.\n- Fluent in both English (pro level) and French.\n- Good proficiency with SQL.\n- Strong team player, actively contributing to continuous improvement and fostering effective collaboration.\n- Proactive approach to continuous technical exploration, with a keen interest in implementing new technologies and innovative solutions, including prototyping.\n- Ability to draft technical specifications and good understanding of data modeling techniques (star, snowflake, medallion etc).\n- Hands-on experience in building and managing analytics pipelines.\n- Capable of making informed decisions based on business opportunities.\n- Proficiency in at least one of the following programming languages : Python, Golang (preferred) or Java\n- Hands-on experience with cloud-based data warehouses, particularly BigQuery/Snowflake.\n- Proficiency in monitoring data quality of datasets and investigating discrepancies\n- Good level knowledge on how to analyze, design, or improve the efficiency, scalability, and stability of data collection, storage, and retrieval processes.\n\nIf you meet these qualifications and are passionate about leveraging data to drive insights and innovation, we encourage you to apply.",
        "link": "https://www.hellowork.com/fr-fr/emplois/61723726.html"
    },
    {
        "title": "Senior Analytics Engineer H/F",
        "entreprise": "Mirakl",
        "localisation": "Paris - 75",
        "contrat": "CDI",
        "description": "Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l'ergonomie...\n\nElles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l'ensemble des produits.\n\nToutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au coeur de notre philosophie.\n\nEt pour favoriser ce partage avec d'autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\n\nA propos du job\n\nEn tant que Senior Analytics Engineer, vous jouerez un rôle clé dans la construction et l'optimisation des modèles de données, des pipelines et des solutions afin de favoriser la prise de décisions basée sur les données dans toute l'organisation.\nEn travaillant sur notre Data Platform, vous ferez le lien entre la Data Engineer et Data Analyst en fournissant des solutions évolutives, maintenables et performantes.\n\nAu quotidien, vous allez :\n- Concevoir, implémenter et maintenir des pipelines ETL/ELT robustes sur Databricks, en garantissant la fiabilité, la scalabilité et les performances des données.\n- Développer et optimiser du code SQL et Python pour transformer des données brutes en ensembles de données propres et réutilisables pour l'analyse et le reporting.\n- Construire et maintenir des tableaux de bord Superset pour fournir des insights exploitables aux différents stakeholders.\n- Contribuer au développement de modèles de données et maintenir une source unique de vérité dans l'organisation.\n- Collaborer étroitement avec les Data Analysts, Data Engineers et les équipes produit pour aligner les priorités et capacités.\n- Utiliser Scala si nécessaire pour des transformations et traitements avancés des données entre les couches Silver et Gold.\n- Assurer la qualité et la gouvernance des données en mettant en oeuvre les meilleures pratiques de test, de documentation et de monitoring.\n\nVous aimerez ce job si :\n- Vous avez un minimum 6 années d'expérience en tant que Data/Analytics Engineer ou dans un rôle similaire.\n- Vous maîtrisez SQL et Python, avec de l'expérience dans la conception et l'optimisation de requêtes et scripts complexes.\n- Vous avez une expérience pratique avec Databricks/AWS ou des plateformes de données similaires.\n- Vous avez de l'expérience dans la création de tableaux de bord sur Superset ou des outils BI similaires.\n- Vous connaissez dbt et les pratiques modernes de modélisation des données.\n- Vous avez de solides compétences en résolution de problèmes, attention aux détails et capacité à travailler dans un environnement dynamique.\n- Vous avez de bonnes compétences en communication pour collaborer avec des parties prenantes techniques ou non.\n\nLe petit +\n- Expérience préalable avec Scala.\n\nCe que nous proposons :\n- L'opportunité de travailler avec des technologies récentes.\n- Un environnement d'équipe collaboratif, innovant et bienveillant.\n- Des opportunités de développement professionnel et un accès à des formations avancées.\n- La chance d'avoir un impact significatif au sein d'une organisation data driven.\n\nEnvie de nous rejoindre ?\n- Un appel téléphonique de 30 minutes avec l'un de nos recruteurs Tech. Ce sera l'occasion de discuter de votre parcours, de vos attentes et de découvrir ce que Mirakl peut vous offrir.\n- Un cas pratique à faire chez vous\n- Un entretien technique d'1H via Zoom avec un membre de l'équipe Data, pour débriefer du cas pratique et explorer concrètement votre expertise et comment vos compétences peuvent contribuer à nos projets.\n- 2 entretiens de 45 minutes via Zoom avec vos futurs collègues chez Mirakl pour discuter de nos valeurs et de notre culture d'entreprise.\n\nMirakl est engagée en faveur de la diversité, de l'égalité des chances et de l'inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d'innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.",
        "link": "https://www.hellowork.com/fr-fr/emplois/60314341.html"
    },
    {
        "title": "Senior Analytics Engineer All Genders H/F",
        "entreprise": "Dailymotion",
        "localisation": "Paris - 75",
        "contrat": "CDI",
        "description": "Dailymotion is seeking a Senior Analytics Engineer to join the Data & Analytics Engineering Teams. Our craft is responsible for most of the Data products at Dailymotion; your work will have an impact throughout Dailymotion's business and help make data-driven decisions on products and strategy.\n\nYou'll join the Data & Analytics Engineering craft at Dailymotion, to create and maintain data products. The Analytics Engineering team focuses on providing reliable data for analysis company wide. This includes building and managing our multi-petabyte data warehouse, highly scalable client-facing analytics, data ingestion & distribution, and data synchronization systems. As a Senior Analytics Engineer, you'll blend software engineering and data skills to maintain code and model data effectively. If you're eager to solve challenging business problems, this role offers a broad impact across all of Dailymotion's businesses.\n\nOur stack runs almost exclusively on Google Cloud Platform. You will work in an environment made up of Data Lakes (BigQuery, etc.), orchestration and scheduling platforms (Airflow), container-oriented deployment, and management platforms (Docker, K8S, JenkinsX), SQL, Data Quality Tools (DBT, Sifflet). You will also participate in data modeling activities and design of data flows until their implementation and support in production.\n- Expose the data through various means such as datamarts, and flat files for both internal and external users.\n- Build complex and efficient SQL queries to transform data within our data lake into reliable business entities and reporting aggregates. Identify and manage dependencies for these transformations, scheduling them using tools like Airflow.\n- Investigate discrepancies and quality issues in the data, as well as addressing performance issues.\n- Design optimized and cost-efficient data models in BQ while addressing business use cases.\n- Ensure data cleanliness, consistency, and availability by performing data quality checks and implementing monitoring.\n- Catalog and document various aspects of the data, including business entities, datamarts, dimensions, metrics, and business rules.\n- Serve as a subject matter expert on business entities and datamarts, providing training to users on SQL and analytics best practices (collaboration with Business Insight).\n- Innovate by proposing new tools, processes, documentation, and exploring emerging technologies during designated cool-down periods.\n\n- Minimum 5 years of experience in Data Analytics.\n- Fluent in both English (pro level) and French.\n- Advanced SQL skills\n- Strong leader, actively contributing to continuous improvement and fostering effective collaboration.\n- Proactive approach to continuous technical exploration, with a keen interest in implementing new technologies and innovative solutions, including prototyping.\n- Strong ability to draft technical specifications and strong understanding of data modeling techniques (e.g star, snowflake, medallion)\n- Hands-on experience in building and managing analytics pipelines.\n- Capable of making informed decisions based on business opportunities.\n- Proficiency in at least one of the following programming languages : Python, Golang (preferred) or Java\n- Advanced experience with cloud-based data warehouses, particularly BigQuery/Snowflake and how to optimize their costs\n- Proficiency in monitoring data quality of datasets and investigating discrepancies\n- Good level knowledge on how to analyze, design, or improve the efficiency, scalability, and stability of data collection, storage, and retrieval processes.\n- Demonstrated ability to mentor and guide junior team members\n\nIf you meet these qualifications and are passionate about leveraging data to drive insights and innovation, we encourage you to apply.",
        "link": "https://www.hellowork.com/fr-fr/emplois/61528477.html"
    },
    {
        "title": "Si vous étiez notre Prochain H/F",
        "entreprise": "Compagnie des Alpes",
        "localisation": "Paris 9e - 75",
        "contrat": "CDI",
        "description": "En tant que Lead Tech Data marketing automation, vous serez responsable de la conception, du développement et de la maintenance des solutions de data marketing et de marketing automation pour les parcs de loisirs de la compagnie des alpes.\n\nVous travaillerez en étroite collaboration avec les équipes marketing, CRM, digital et data pour définir les besoins, les spécifications et les indicateurs de performance des campagnes marketing et des parcours clients.\n\nVous piloterez une équipe de 3 personnes, composée d'un data engineer talend, d'un data engineer Databricks et d'un PO, en assurant la coordination, la montée en compétences et l'évaluation de leurs activités.\n\nVous serez le référent technique sur les technologies databricks, pyspark, talend et powerbi, qui sont les outils principaux utilisés pour la collecte, le traitement, l'analyse et la visualisation des données marketing.\n\nVos missions\n- Concevoir et développer des pipelines de données et des workflows de marketing automation, en utilisant les technologies databricks et talend, pour alimenter les bases de données marketing, les plateformes CRM et les outils de communication.\n- Assurer la qualité, la fiabilité et la sécurité des données marketing, en respectant les normes, les bonnes pratiques et la réglementation en vigueur.\n- Veiller à la veille technologique et à la formation continue de l'équipe, en identifiant les opportunités d'amélioration et d'innovation.",
        "link": "https://www.hellowork.com/fr-fr/emplois/59197861.html"
    },
    {
        "title": "Ingénieur Big Data H/F",
        "entreprise": "Cgilanum",
        "localisation": "Paris 1er - 75",
        "contrat": "CDI",
        "description": "CGILANUM recherche en CDI des ingénieurs disposant d'une expertise technique sur le Big Data.\n\nVous aurez la possibilité d'évoluer sur des projets variés et innovants dans différents secteurs notamment la banque et l'assurance.\n\nPassionné(e) des nouvelles technologies, curieux(se), motivé(e), vous avez l'esprit d'équipe. Votre sens du service, votre créativité associée à un esprit méthodique vous offriront des possibilités d'évolution vers le management de projet, l'expertise technique ou fonctionnelle.\n\nVous disposez d'au moins 5 ans d'expérience en développement autour des technologies HADOOP, HDFS, SPARK, HORTONWORKS, HIVE, Big Query, DATABRICKS, SNOWFLAKE, Azure Data Factory, MAPREDUCE, YARN, SQOOP, CASSANDRA, MONGODB, HBASE, KAFKA, ELASTICSEARCH, LOGSTASH, KIBANA, FLUME, LINUX, STORM, FLINK, BEAM, IMPALA, ZOOKEEPER, SENTRY, RANGER, HUE, OOZIE JAVA, SCALA, GO, PYTHON, R, AWS.\n\nCGILANUM, cabinet parisien d'expertise et de conseil, est spécialisé dans le développement d'applications Web, la BI/Big Data et l'AMOA autour de la transformation digitale.",
        "link": "https://www.hellowork.com/fr-fr/emplois/61489695.html"
    },
    {
        "title": "Ingénieur Big Data H/F",
        "entreprise": "SOMA",
        "localisation": "Paris - 75",
        "contrat": "CDI",
        "description": "Afin d'accompagner la forte croissance de SOMA, nous sommes à la recherche de Data Engineers.\n\nTa mission\n\nEn tant que Data Engineer, tu participeras à la conception, la construction, le déploiement et le maintien en production d'architectures Big Data, ces dernières ayant pour objectif de permettre tant l'évolution que l'optimisation du système d'information décisionnel existant en permettant de nouveaux usages Analytics et IA. Nous opérons au travers de cinq practices internes, incluant Data Platform Services, où nos consultants apportent leur expertise sur des environnements Big Data complexes.\n\nTes principales responsabilités\n- Concevoir, développer et maintenir des pipelines de données dans des environnements Big Data à l'aide de PySpark et Snowpark.\n- Optimiser les performances des bases de données, en garantissant une gestion efficace des données.\n- Développer des architectures data robustes et scalables pour répondre aux besoins métiers et aux volumes croissants de données.\n- Participer à la mise en place des bonnes pratiques en matière de gestion de données (gouvernance, qualité, sécurité).\n- Collaborer avec les équipes Data Science et BI pour intégrer les données dans les solutions analytiques.\n- Réaliser une veille technologique pour intégrer les meilleures pratiques et les outils les plus récents dans vos projets.\n\nSelon ton appétence et les besoins sur les sujets Data, tu as la possibilité de monter une communauté Data interne, c'est à dire :\n- Intervenir sur des réponses à appel d'offre\n- Intervenir sur des phases d'avant-vente\n- Animer ou contribuer au développement des communautés (pratiques, veille, formation...)",
        "link": "https://www.hellowork.com/fr-fr/emplois/61278439.html"
    },
    {
        "title": "Analytics Engineer H/F",
        "entreprise": "SOMA",
        "localisation": "Paris - 75",
        "contrat": "CDI",
        "description": "Afin d'accompagner la forte croissance de SOMA, nous sommes à la recherche de Analytics Engineer Data\n\nMission :\n\nEn tant qu'Analytics Engineer Senior, tu joueras un rôle clé dans le développement et l'optimisation des solutions analytiques de nos clients. Tu seras également impliqué dans des missions variées grâce à ta polyvalence et ton expertise en améliorant continuellement les processus de prise de décision basés sur la data.\n\nResponsabilités principales :\n- Concevoir, développer et maintenir des pipelines de données robustes pour garantir la qualité et la fiabilité des données.\n- Développer et optimiser des tableaux de bord et des visualisations avancées (Tableau, Power BI ou autres outils similaires) pour traduire les données en insights exploitables.\n- Collaborer avec les équipes Data Science, IT et métiers pour comprendre les besoins clients et proposer des solutions analytiques adaptées.\n- Savoir extraire, transformer et charger (ETL) des données dans les systèmes appropriés.\n- Structurer et modéliser les données pour répondre aux besoins analytiques (data modeling, optimisation des entrepôts de données).\n- Mettre en place des bonnes pratiques en matière de gouvernance des données et de gestion des bases de données.\n- Accompagner les équipes dans l'adoption des outils de data visualisation et des solutions analytiques.\n- Participer activement à la veille technologique et à l'amélioration continue des solutions déployées.\n\nSelon ton appétence et les besoins sur les sujets Data, tu as la possibilité de monter une communauté Data interne, c'est-à-dire :\n- Intervenir sur des réponses à appel d'offre\n- Intervenir sur des phases d'avant-vente\n- Animer ou contribuer au développement des communautés (pratiques, veille, formation...)",
        "link": "https://www.hellowork.com/fr-fr/emplois/61277951.html"
    },
    {
        "title": "Saint Laurent Analyst Engineer Intern W - m H/F",
        "entreprise": "Kering",
        "localisation": "Paris - 75",
        "contrat": "CDI",
        "description": "Description de poste\n\nROLE\n\nAs an Analyst Engineer Intern, you will BE an integral part of our Data team, tasked with uncovering insights and developing models that spotlight usages and drifts of our data assets. Your work will BE critical in driving our data-centric approach to decision-making and will directly contribute to the strategic direction of our data platform.\n\nMISSION\n- Data Exploration Explore large and complex datasets to extract meaningful insights on the data usage, in order to pilot our data platform strategy. Use your analytical skills to interpret data and translate trends and patterns into actionable insights.\n- Data product development : Create and refine modes that gives relevant insights regarding the data platform assets usage (drift, usage, assets management, access management). These models will serve as a foundation to take decision on the future development of the data product assets.\n- Collaboration : Work closely with a lead data engineer, the group data platform team and other stakeholders to understand the needs and how your work can support their objectives. You'll BE expected to translate technical findings into understandable insights that can BE acted upon.\n- Presentation of Findings : Develop reports and visualizations that clearly communicate your findings to both technical and non-technical audiences, ensuring that key insights are accessible and actionable.\n\nPROFILE\n- Master's degree in data engineering, looking for a final year internship.\n- Proficiency in SQL, Google Cloud Platform Services and PowerBI\n- Skills on dbt or terraform is a plus\n- Technical skills such as data modeling, database manipulation, development best practices and architecture patterns.\n- Familiar with Data Mesh architecture\n- Good analytical skills to identify risks and opportunities.\n- Proficiency in Office software (primarily Excel and PowerPoint)\n- You are curious, proactive, and rigorous.\n- You are fluent in English and French, both written and spoken, and can work in a multicultural and multilingual environment.\n\nInternship of 6 months to meet in March 2025.\n\nSaint Laurent is committed to creating a diverse workforce. We believe that diversity in all its forms - gender, age, nationality, culture, religious beliefs and sexual orientation - enriches the workplace. IT opens opportunities for people to express their talents, both individually and collectively, and helps to strengthen our ability to adapt to a changing world. As an equal opportunities' employer, we welcome and consider applications from all qualified candidates, regardless of their background.\n\nType de contrat\nStagiaire (durée déterminée) (stagiaire)\n\nDate de début\n2025-03-03\n\nTemps plein/Temps partiel\nTemps plein\n\nOrganisation\nYves Saint Laurent SAS",
        "link": "https://www.hellowork.com/fr-fr/emplois/57721144.html"
    },
    {
        "title": "Lead Analytics Engineer All Genders H/F",
        "entreprise": "Dailymotion",
        "localisation": "Paris - 75",
        "contrat": "CDI",
        "description": "Dailymotion is seeking a Lead Analytics Engineer to join the Data & Analytics Engineering Teams. Our craft is responsible for most of the Data products at Dailymotion; your work will have an impact throughout Dailymotion's business and help make data-driven decisions on products and strategy.\n\nYou'll join the Data & Analytics Engineering craft at Dailymotion, to create and maintain data products. The Analytics Engineering team focuses on providing reliable data for analysis company wide. This includes building and managing our multi-petabyte data warehouse, highly scalable client-facing analytics, data ingestion & distribution, and data synchronization systems. As a Lead Analytics Engineer, you'll lead the design of complex analytics systems, guide technical strategies, and mentor team members while maintaining a direct impact on business outcomes.\n\nResponsibilities :\n\nOur stack runs almost exclusively on Google Cloud Platform. You will work with technologies such as Data Lakes (BigQuery, etc.), orchestration and scheduling platforms (Airflow), containerized deployment (Docker, K8S, JenkinsX), SQL, and Data Quality Tools (DBT, Sifflet). You will also participate in data modeling activities and design of data flows until their implementation and support in production.\n- Define and implement the technical vision for analytics engineering, aligning with organizational goals.\n- Lead the design, development and optimization of analytics pipelines and data models to support high-impact business needs.\n- Provide leadership and guidance to the analytics engineering team, fostering a culture of collaboration, growth and innovation.\n- Partner with cross-functional teams (Business Insights, Product, Engineering) to gather requirements and deliver actionable insights.\n- Establish and enforce best practices for data quality, pipeline reliability and system performance.\n- Oversee the cataloging of data entities, dimensions and metrics while promoting consistent usage across the organization\n- Drive the adoption of emerging technologies and tools, ensuring the team stays at the forefront of analytics engineering industry\n\nMonitor and optimize the cost of data infrastructure, ensuring efficient resource usage\n\nRequired skills :\n- 7+ years in data analytics or a related field, with at least 2 years in a leadership role.\n- Proven track record of leading technical projects, defining strategies, and delivering results.\n- Experience managing and mentoring engineering teams, with the ability to foster a collaborative and high-performing environment.\n- Strong capability in designing, optimizing, and executing complex SQL queries.\n- Proficiency in at least one programming language (Python, Golang preferred, or Java), with a focus on reusable and scalable code.\n- Deep knowledge of data modeling techniques (e.g., star, snowflake, medallion) and their practical applications.\n- Advanced experience with platforms such as BigQuery or Snowflake, including cost optimization strategies.\n- Proven ability to implement data quality frameworks and troubleshoot complex data discrepancies.\n- Strong interpersonal skills to engage with stakeholders, translate business needs into technical solutions, and ensure alignment.\n- Demonstrated ability to evaluate, adopt, and champion new tools and technologies.\n- Expert in optimizing the efficiency, scalability, and cost of data systems.\n\nIf you meet these qualifications and are passionate about leveraging data to drive insights and innovation, we encourage you to apply.",
        "link": "https://www.hellowork.com/fr-fr/emplois/61211618.html"
    },
    {
        "title": "Data Ops H/F",
        "entreprise": "Bluecoders",
        "localisation": "Paris 11e - 75",
        "contrat": "CDI",
        "description": "Dans le cadre de la forte croissance et du développement international de notre client, nous vous offrons l'opportunité de rejoindre une entreprise au coeur des révolutions du e-commerce et du Big Data. En tant que Data Ops (H/F), vous jouerez un rôle central dans l'optimisation et l'innovation de produits ultra-personnalisés, qui connectent les grandes marques à leurs consommateurs via des expériences engageantes et uniques. Grâce à ses technologies propriétaires et son expertise en données issues des tickets de caisse, notre client transforme le retail en France et en Europe. Votre mission : Rattaché(e) au Lead Infra, vous serez au coeur de projets stratégiques et aurez pour rôle d'innover en matière de data engineering et ops pour développer des services à forte valeur ajoutée. Mais aussi d'optimiser les performances des pipelines de données et des processus ETL avec des outils de pointe. Et pour finir, Collaborer avec des équipes pluridisciplinaires pour proposer des solutions qui redéfinissent les standards du e-commerce.\n\nVotre profil *Maîtrise de langages structurés (Python) et des bases de données (BigQuerry).\n\n*Maîtrise de Airflow. *Connaissances solides en architecture réseau et en administration de systèmes (Linux/Ubuntu/Apache/Nginx)\n\n*Expérience avec une plateforme Cloud (GCP) et dans des méthodologies de développement informatique (tests unitaires, revue de code).\n\n*Curiosité et capacité d'adaptation dans un environnement en évolution rapide.\n\n*Bac +5 (école d'ingénieur ou équivalent) avec 4 ans minimum d'expérience en data engineering. *Anglais courant indispensable.\n\nNotre client est spécialisé dans l'engagement des consommateurs à travers des solutions technologiques sur mesure et innovantes. Il transforme les données en expériences uniques pour connecter les grandes marques à leurs clients et relever les défis du commerce en ligne. Son expertise : *Big Data et intelligence artificielle : Exploitation et analyse de données pour offrir des activations ultra-personnalisées. *Solutions ludiques et efficaces : Des outils qui allient innovation et performance pour répondre aux attentes du e-commerce moderne. *Impact significatif : Des millions de consommateurs engagés chaque année grâce à ses activations développées pour des leaders de la grande distribution et des marques internationales. Pourquoi les rejoindre ?\n*Avec plus de 11,9 millions de consommateurs engagés à travers des activations ludiques et sur mesure, et une présence auprès des plus grands distributeurs (Intermarché, Carrefour, Leclerc, Coca-Cola, etc.), notre client est un acteur incontournable de l'e-retail. *Une croissance annuelle à deux chiffres, portée par une expertise unique dans l'analyse et l'activation de données. *Vous intégrerez une équipe passionnée et stimulante, guidée par des valeurs fortes : leadership, simplicité, et obsession du consommateur. *Profitez d'une culture d'entreprise unique, alliant travail d'excellence et moments de convivialité, au coeur de Paris.",
        "link": "https://www.hellowork.com/fr-fr/emplois/61024639.html"
    },
    {
        "title": "Ingénieur Data Senior 6+ Ans d'Expérience Minimum H/F",
        "entreprise": "IOTA GROUP",
        "localisation": "Paris - 75",
        "contrat": "Indépendant/Freelance",
        "description": "Responsabilités principales :\n\nIngestion de données :\n- Développer et optimiser les pipelines de données en utilisant AWS Glue, Step Functions et Lambda.\n- Garantir la performance des flux d'ingestion grâce à l'application des bonnes pratiques, telles que le caching, la persistence, le partitioning, et la définition dynamique des schémas.\n\nOptimisation des pipelines :\n- Mettre en oeuvre des techniques avancées avec PySpark pour optimiser les traitements.\n\nQualité et gouvernance des données :\n- Maintenir ou mettre en place des politiques robustes de gestion et de qualité des données.\n- Développer des solutions modulaires et encapsulées pour une meilleure gestion des environnements.\n\nOrchestration et gestion des workflows :\n- Configurer et gérer les pipelines d'ingestion en utilisant GitHub Actions (multi-branches, triggers, conditions, workflows, jobs).\n\nMonitoring et journalisation :\n- Mettre en place des mécanismes de suivi via AWS CloudWatch pour monitorer et détecter les anomalies.\n- Développer des fonctionnalités enrichissant le monitoring des données (par exemple, ajout de logs avancés).\n\nValidation et documentation :\n- Assurer la mise en place de tests unitaires et d'intégration pour garantir la fiabilité des pipelines.\n- Rédiger une documentation technique complète incluant les schémas, types de données, tables, et processus d'évolution.\n\nCompétences requises (Must Have) :\n\nExpérience :\n- Minimum 6 ans d'expérience dans le Data Engineering.\n\nMaîtrise des technologies AWS :\n- AWS Glue : Expertise avérée dans l'utilisation et l'optimisation.\n- AWS S3 : Gestion du stockage des données et mise en place de politiques de rétention.\n- AWS Lambda et Step Functions : Pour l'orchestration et les traitements asynchrones.\n- AWS CloudWatch : Pour le monitoring des pipelines.\n\nCompétences techniques :\n- Python et PySpark : Maîtrise des langages pour le développement et l'optimisation des traitements.\n- Git : Gestion avancée des workflows Git, y compris les GitHub Actions avec des multi-branches, triggers et jobs complexes.\n- Tests et validation : Conception et mise en oeuvre de tests unitaires et d'intégration.\n- Documentation technique : Rédaction claire et précise des spécifications techniques.\n\nCompétences supplémentaires (Nice to Have) :\n- Connaissance d'autres services AWS, tels que :\n- SNS : Notifications.\n- Inspector : Analyse de sécurité.\n- Secret Manager : Gestion des secrets.\n- Athena : Requêtage SQL sur S3.\n- Utilisation de branches Git dans Databricks.\n- Connaissance des outils d'analyse de qualité de code comme Checkmarx et SonarQube.\n\nCe poste offre une opportunité unique de travailler sur des projets critiques en exploitant les technologies les plus avancées du Cloud AWS. Si vous êtes un expert en Data Engineering avec une passion pour l'innovation et l'optimisation, nous serions ravis de vous accueillir dans notre équipe.\n\nType de contrat : Freelance ou CDIC\nLocalisation : Télétravail partiel possible selon les besoins du projet\nLangue : Français courant",
        "link": "https://www.hellowork.com/fr-fr/emplois/60936802.html"
    },
    {
        "title": "Développeur Fullstack Javascript Freelance H/F",
        "entreprise": "Kicklox",
        "localisation": "Paris - 75",
        "contrat": "Indépendant/Freelance",
        "description": "L'offre\n\nProjet\nDéveloppement registre de crédits carbone\n\nSecteurs\nEnergie, Digital & E-Commerce\n\nDescription de l'offre\n\nNous sommes à la recherche d'un(e) développeur(euse) capable de s'intégrer rapidement à notre équipe pour accélérer nos releases sur les 4 à 6 prochains mois.\n\nMissions à réaliser\n\nTu rejoindras l'équipe pour renforcer le développement de notre registre de crédits carbone, qui gère toutes les transactions financières des crédits carbone que nous certifions. Ton rôle principal sera de contribuer activement à l'amélioration et à l'extension de cette plateforme essentielle pour notre mission, en développant une nouvelle interface utilisateur. Dans un second temps, tu seras amené(e) à travailler sur le développement d'une API externe.\n\nL'équipe est composée de 3 développeurs, 1 data engineer, 1 PM, et 1 designer. Nous travaillons de manière collaborative et agile pour livrer des solutions efficaces.\n\nLivrables attendus\n- Modalités\n- Date de démarrage : dès que possible\n- Date de fin : durée 6 mois\n- Candidats recherchés : 1\n- Expérience : 5+ ans\n- Type de contrat : Freelance / Indépendant, Temps complet\n- Rémunération : 150 € - 500 € par jour selon expérience\n- Mode de facturation : Assistance technique\n- Localisation : Paris, France\n- Télétravail partiel",
        "link": "https://www.hellowork.com/fr-fr/emplois/60929193.html"
    },
    {
        "title": "Consultant expérimenté Data Strategy & Governance | CDI | H/F",
        "entreprise": "PwC",
        "localisation": "Neuilly",
        "contrat": "Non précisé",
        "description": "Line of Service\nAdvisory\nIndustry/Sector\nNot Applicable\nSpecialism\nData, Analytics & AI\nManagement Level\nSenior Associate\nJob Description & Summary\nPwC poursuit sa stratégie mondiale The New Equation, portée par l’humain, nos engagements responsables, sociétaux et soutenus par la technologie. Dans ce contexte, nous investissons sur l’utilisation du cloud, de l’IA, des alliances technologiques, de la réalité virtuelle et de technologies émergentes.\n\n\n\n\n\n\n\n\n\n\nDegrees/Field of Study required:\nDegrees/Field of Study preferred:\nNot Specified\nNo\nNo",
        "link": "https://www.glassdoor.fr/job-listing/consultant-exp%C3%A9riment%C3%A9-data-strategy-governance-cdi-hf-pwc-JV_IC3041419_KO0,54_KE55,58.htm?jl=1009093458724"
    },
    {
        "title": "Tech lead Cloud Data Engineer F/H",
        "entreprise": "Malakoff Humanis",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "Société\nASSOCIATION DE MOYENS ASSURANCE DE PERSONNES\nDescription du poste\nMétier\nDEVELOPPEMENT - TECHLEAD\nIntitulé du poste\nTech lead Cloud Data Engineer F/H\nContrat\nContrat à durée indéterminée\nFinalité du poste\nMALAKOFF HUMANIS est un groupe paritaire, mutualiste et à but non lucratif, leader sur le marché de la protection sociale (Santé, Prévoyance, Epargne, Retraite) en France. Nous recherchons régulièrement de nouveaux talents pour contribuer à notre stratégie d’entreprise.\n\nChez MALAKOFF HUMANIS, nous sommes convaincus que notre force est la somme de toutes nos différences.\n\nProtéger, accompagner, innover : découvrez en plus sur notre raison d’être.\n\n\n\nChez Malakoff Humanis et en intégrant la Direction Data du pôle MH Tech, vous avez pour rôle, dans votre position de référent technique, de coordonner les équipes techniques en charge de la mise au point des composants nécessaires au développement et optimisation de l’écosystème Datalake du groupe (avec des usages et des finalités différents).\n\nVous intervenez en position d’expert des cadres de développement pour « designer » des solutions techniques aptes à garantir la performance de la solution livrée. Vous veillez à la fois au respect des standards de développement et à la cohérence des architectures techniques.\n\nAu sein des équipe SI Data de MH Tech, vous rejoignez l’équipe Développement Solutions IT et Management Data, composée de 6 collègues. Le rôle de l’équipe est de prendre en charge la mise à disposition de l’infrastructure (Datalake, Datalakehouse, …), l’activation des services ainsi que le support, en transverse pour les utilisateurs en lien avec les métiers.",
        "link": "https://www.glassdoor.fr/job-listing/tech-lead-cloud-data-engineer-fh-malakoff-humanis-JV_IC2881970_KO0,32_KE33,49.htm?jl=1009302691257"
    },
    {
        "title": "Quality Assurance Engineer",
        "entreprise": "Therapxiel",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "Quality Assurance Engineer\nTherapixel - a leading software company specializing in Artificial Intelligence applied to medical imaging.\nOur goal is to provide radiologists with innovative software, designed with a high level of safety, quality, and performance, to help them improve their clinical practice.\nWe are a multicultural, dynamic, and dedicated team.\nWe create a challenging work environment driven by talented people who share the same vision and passion.\nOur strong sense of mutual commitment creates synergy pushing away all medical imaging limits.\nDiscover our journey and culture on \"therapixel.com\" and our product on \"mammoscreen.com\"!\nA newly created position to to reinforce our Quality Assurance team.",
        "link": "https://www.glassdoor.fr/job-listing/quality-assurance-engineer-therapxiel-JV_IC2881970_KO0,26_KE27,37.htm?jl=1009626732793"
    },
    {
        "title": "Technical Leader Sensitivities & Repository - Big Data (F/H)",
        "entreprise": "Natixis",
        "localisation": "Charenton",
        "contrat": "Non précisé",
        "description": "Institution financière internationale de premier plan, Natixis Corporate & Investment Banking met à disposition des entreprises, institutions financières, fonds d'investissement, agences souveraines et supranationales une palette de services en conseil, investment banking, financements, banque commerciale et sur les marchés de capitaux.\nSes équipes d'experts, présentes dans environ 30 pays, conseillent les clients sur leur développement stratégique en les accompagnant dans le développement et la transformation de leurs activités tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'engage sur un alignement de son portefeuille de financements sur une trajectoire de neutralité carbone d'ici à 2050, tout en aidant ses clients à réduire l'impact environnemental de leur activité.\nNatixis Corporate & Investment Banking fait partie du Groupe BPCE, deuxième groupe bancaire en France à travers les réseaux Banque Populaire et Caisse d'Epargne. Elle bénéficie de la puissance financière et des solides notations du Groupe (Standard & Poor's : A+, Moody's : A1, Fitch Ratings: A+, R&I : A+).",
        "link": "https://www.glassdoor.fr/job-listing/technical-leader-sensitivities-repository-big-data-fh-natixis-JV_IC3019638_KO0,53_KE54,61.htm?jl=1009638666820"
    },
    {
        "title": "Backend Developer (Python) – API & System Integration Specialist",
        "entreprise": "NOOTA",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "Who We Are\nJoin Noota, a leader in AI-powered automation for professional conversations, revolutionizing how businesses handle recruitment, sales, and workflow automation. With 70,000+ users across 50 countries, our platform integrates deeply with ATS, CRM, HR, and productivity tools, enabling seamless AI-driven interactions.\nWe are scaling our backend team to push the limits of AI automation and deepen integrations with our partners. This role is perfect for an engineer passionate about API architecture, workflow automation, and AI-powered actions, driving real-world impact for thousands of professionals.\nWhat We Offer\nAt Noota, we are revolutionizing the way professionals interact with AI-driven note-taking and workflow automation. As a Backend Developer, you will play a crucial role in building and scaling the backend infrastructure that powers our product. You will ensure high performance, reliability, and seamless integration with various platforms while working in a fast-paced, high-growth startup environment.",
        "link": "https://www.glassdoor.fr/job-listing/backend-developer-python-api-system-integration-specialist-noota-JV_IC2881970_KO0,58_KE59,64.htm?jl=1009645695570"
    },
    {
        "title": "Manager Data Product Owner – Energy, Utilities, Industrial Product & Services | CDI | H/F",
        "entreprise": "PwC",
        "localisation": "Neuilly",
        "contrat": "Non précisé",
        "description": "Line of Service\nAdvisory\nIndustry/Sector\nNot Applicable\nSpecialism\nData, Analytics & AI\nManagement Level\nManager\nJob Description & Summary\nPwC poursuit sa stratégie mondiale The New Equation, portée par l’humain, nos engagements responsables, sociétaux et soutenus par la technologie. Dans ce contexte, nous investissons sur l’utilisation de la Data, du C loud, de l’IA, des alliances technologiques et de s technologies émergentes.\n\n\n\n\n\n\n\n\nDegrees/Field of Study required:\nDegrees/Field of Study preferred:\nAccepting Feedback, Accepting Feedback, Active Listening, Analytical Thinking, Business Case Development, Business Development, Business Expansion, Business Model Development, Business Transformation, Channel Partner Management, Coaching and Feedback, Communication, Creativity, Customer Analysis, Customer Engagement, Customer Experience (CX) Strategy, Customer Insight, Customer Relationship Management, Customer Retention, Customer Service, Customer Strategy, Customer Success, Customer Transformation, E-Commerce, Embracing Change {+ 22 more}\nNot Specified\nNo\nNo",
        "link": "https://www.glassdoor.fr/job-listing/manager-data-product-owner-energy-utilities-industrial-product-services-cdi-hf-pwc-JV_IC3041419_KO0,78_KE79,82.htm?jl=1009348280923"
    },
    {
        "title": "INGENIEUR INTELLIGENCE AUGMENTEE H/F CDI",
        "entreprise": "Guerbet",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "At Guerbet, we build lasting relationships so that to enable people to live better. This is Our Purpose.\nWe are a global leader in medical imaging, offering an extensive portfolio of pharmaceuticals, medical devices, digital and AI solutions, for diagnostic and interventional imaging. As a pioneer in the field of contrast products since the last 95 years ,we continuously innovate. We dedicate 10% of our revenue to Research & Development such as to improve the diagnosis, prognosis and quality of life of patients.\nAchieve, Cooperate, Care and Innovate are the values that we share and practice on a daily basis.\nWorking at Guerbet is not only being part of a multicultural team of 2,600 people across more than 20 countries, but, it is above all about playing a unique role in the future of medical imaging.\nFor more information on Guerbet, go to www.guerbet.com and follow Guerbet on Linkedin, Twitter, Instagram and Youtube",
        "link": "https://www.glassdoor.fr/job-listing/ingenieur-intelligence-augmentee-hf-cdi-guerbet-JV_IC2881970_KO0,39_KE40,47.htm?jl=1009647304002"
    },
    {
        "title": "Product Quality Assurance Engineer",
        "entreprise": "Melexis Microelectronic Systems",
        "localisation": "Corbeil-Essonnes",
        "contrat": "Non précisé",
        "description": "YOUR FUTURE JOB\nAs a Product Quality Assurance Engineer at Melexis, you’ll be at the forefront of ensuring our cutting-edge products perform seamlessly throughout their lifecycle. By combining your expertise in quality, efficiency, and innovation, you’ll play a pivotal role in delivering excellence to our customers. This is your chance to join a collaborative, forward-thinking team that values your contributions and empowers you to grow.\nMore specifically, you will\nEnsure the enhancement of product and system performances in terms of quality, time and cost efficiency throughout product life time\nConduct the necessary steps in the solution finding process of internal non conformities",
        "link": "https://www.glassdoor.fr/job-listing/product-quality-assurance-engineer-melexis-microelectronic-systems-JV_IC3014111_KO0,34_KE35,66.htm?jl=1009535325694"
    },
    {
        "title": "Data Engineer (H/F) - CDI",
        "entreprise": "BMW",
        "localisation": "Montigny",
        "contrat": "Non précisé",
        "description": "BMW GROUP EN FRANCE : QUI SOMMES-NOUS ?\nBMW Group France abrite les quatre entités BMW France, BMW Finance, BMW Distribution et Alphabet France. Notre mission commune est d'offrir la meilleure expérience à nos clients dans nos marques BMW, MINI et BMW Motorrad.\nLeader des solutions de mobilité destinées aux entreprises, Alphabet est le 3e loueur longue durée multimarques en France et à l’international. La filiale de BMW Group France gère un parc de plus de 103 000 véhicules (particuliers, utilitaires). Autopartage, véhicules électriques, assistant personnel de mobilité, location ponctuelle, covoiturage, vélopartage… Alphabet propose à ses clients des solutions de mobilité innovantes et les accompagne dans leurs plans de mobilité par une expertise en audit et conseil.\nCE QUE VOUS FEREZ AU QUOTIDIEN ?",
        "link": "https://www.glassdoor.fr/job-listing/data-engineer-hf-cdi-bmw-JV_IC2944720_KO0,20_KE21,24.htm?jl=1009644049727"
    },
    {
        "title": "INGENIEUR DATA F/H",
        "entreprise": "Casden - Banque Populaire",
        "localisation": "Champs",
        "contrat": "Non précisé",
        "description": "Description de l'entreprise\nEnvie d'une aventure à taille humaine au sein d'un collectif animé par la satisfaction de nos sociétaires ? Rejoignez la CASDEN Banque Populaire, Banque coopérative de la Fonction Publique.\n\nOutre nos activités bancaires - épargne, crédit et caution - nous menons une politique d'engagement sociétal forte, notamment dans l'éducation, la recherche, la culture, la santé, et l'économie sociale et solidaire.\nL'appartenance au Groupe BPCE - 2ème Groupe bancaire français, vous permettra de construire votre carrière dans un univers varié aux multiples métiers et de relever de nombreux défis.\n\nAu quotidien, nous encourageons l'autonomie, la co-construction, la culture de l'innovation et donnons du sens à la mission de nos collaborateurs.",
        "link": "https://www.glassdoor.fr/job-listing/ingenieur-data-fh-casden-banque-populaire-JV_IC2957097_KO0,17_KE18,41.htm?jl=1009647436150"
    },
    {
        "title": "Stage Data Scientist IA Générative (H/F)",
        "entreprise": "RATP EPIC",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "La RATP recherche un(e) stagiaire Data scientist IA Gen au sein de la Data\nFactory du groupe RATP pour une durée de 6 mois (démarrage entre janvier et avril\n2025).\nAujourd’hui on vous parle d’une opportunité pour rejoindre ce grand groupe qui place\nla data au ❤️ de sa stratégie de performance et de croissance.\nLa DSI fournit des services Digitaux, Industriels et Télécom aux principaux métiers\ndu groupe RATP : systèmes de transport, moyens audio visuels des lignes de métro\nautomatisées, sécurité des biens et des personnes, Information Voyageurs …\nLe SI de la RATP c’est entre autres : 500 applications (systèmes d’information\ncentraux, au service des voyageurs, régulation de trafic…), des domaines métier\nvariés, des équipements de pointe sur le terrain…\nAu sein de la Direction des Systèmes d’Information de la RATP, la Data Factory\nadresse tous les projets transverses à l’entreprise autour des solutions de BI, BIG\nDATA, EPM, Data analytics, DataViz et Data Science. Les solutions mises en place\nadressent à la fois des référentiels de données, des datawarehouses pour les\ndirections opérationnelles, des outillages de simulation/prévisions (masse salariale,\nperformance économique...), un datalake, des algorithmes prédictions (affluence\nvoyageur, géolocalisation matériel roulant, prédictions de panne, analyse\nlinguistique...) et enfin l’ensemble des outils de monitoring des données, data\nlineage, etc...\nLa Data Factory dispose de plusieurs pôles de compétences (Tech Lead, Delivery\nLead, Data Scientists, Data Engineer...) ainsi que les plateformes sur le cloud AWS,\npermettant d'accompagner tous les projets Data.\nVous intégrerez le programme IA générative de la Fabrique digitale et travaillerez en\nbinôme sur cette mission avec un autre data scientist stagiaire. Vous serez\naccompagné et encadré par un ML engineer et une delivery lead (cheffe de projet agile).\nRégion :Ile de France\nStage (durée déterminée) (stagiaire)",
        "link": "https://www.glassdoor.fr/job-listing/stage-data-scientist-ia-g%C3%A9n%C3%A9rative-hf-ratp-epic-JV_IC2881970_KO0,37_KE38,47.htm?jl=1009638381146"
    },
    {
        "title": "Data scientist H∕F Expert Pyspark",
        "entreprise": "Xpert consulting",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "Nous recherchons un(e) Data Scientist (H/F) talentueux(se) pour rejoindre notre équipe. En tant que Data Scientist, vous serez responsable de l'analyse et de l'interprétation des données pour aider à prendre des décisions stratégiques. Vous travaillerez en étroite collaboration avec les équipes techniques et commerciales pour identifier les tendances et les opportunités.\nResponsabilités:\n- Analyser les données volumineuses et complexes pour extraire des informations pertinentes\n- Développer des modèles prédictif\nLe Data Scientist sera chargé de diriger techniquement et d'améliorer les algorithmes du profil de risque, en travaillant sur les aspects suivants :\nProfil de risque existant :\nEffectuer un diagnostic mensuel des résultats obtenus grâce au profil de risque actuel.\nEffectuer des extractions en fonction des besoins métiers.\nÉlaborer un reporting complet avec historisation des données clés pour garantir la traçabilité et l'audibilité.\nStabiliser le profil de risque en automatisant l'ensemble des étapes du processus.\nEnrichissement du profil de risque :",
        "link": "https://www.glassdoor.fr/job-listing/data-scientist-h-f-expert-pyspark-xpert-consulting-JV_IC2881970_KO0,33_KE34,50.htm?jl=1009461871838"
    },
    {
        "title": "Ingénieur Commercial - Data/AMOA/Applicatif (H/F)",
        "entreprise": "Uptoo",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "Effet waouh: Labels rh / prix d'entreprises, Poste évolutif vers du management !, Variable non plafonné\n\nCe qu’on va accomplir ensemble\nVous avez une belle expérience professionnelle dans la prestation de service IT et vous souhaitez intégrer une entreprise aux multiples expertises et talents ?\nDepuis plus de 20 ans, nous accompagnons des acteurs clés de l’économie dans leur transformation digitale du SI, avec des expertises autour du développement applicatif, du pilotage de projets ou encore de la Data.\nL'un de nos axes prioritaires est le renforcement de nos BU Assurance/Finance/Industrie/service, où nous sommes déjà référencés chez de nombreux clients grands comptes.\nCe succès, nous le devons notamment à des collaborateurs passionnés, soudés et engagés. Si vous souhaitez en faire partie, c’est le moment de nous rejoindre. Vous aurez l’occasion de participer à des projets innovants et passionnants !\n\n\n\n\n\n\n\n\n\n\n\nTélétravail 2 jours / semaine",
        "link": "https://www.glassdoor.fr/job-listing/ing%C3%A9nieur-commercial-data-amoa-applicatif-hf-uptoo-JV_IC2881970_KO0,44_KE45,50.htm?jl=1009531999446"
    },
    {
        "title": "Alternance - Ingénieur DATA F/H",
        "entreprise": "Bouygues Telecom",
        "localisation": "Meudon",
        "contrat": "Non précisé",
        "description": "Bouygues Telecom recrute son/sa futur.e Ingénieur Data en alternance.\n\nVous serez basé.e au Technopole de Meudon-la-Forêt (92), situé à deux pas du centre commercial Vélizy 2.\n\nLa Direction des Systèmes d'Information (DSI), s'inscrit au cœur de l'innovation et joue un rôle crucial dans la mise en œuvre des stratégies et des projets de transformation numérique de Bouygues Telecom.\n\nElle est responsable de la planification, de l'acquisition, du développement et de la maintenance des infrastructures et des applications informatiques.",
        "link": "https://www.glassdoor.fr/job-listing/alternance-ing%C3%A9nieur-data-fh-bouygues-telecom-JV_IC3019026_KO0,28_KE29,45.htm?jl=1009645420968"
    },
    {
        "title": "Data Engineer H/F",
        "entreprise": "Nindô Group",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "Chez Nindô, notre voie est claire et pleine de passion !\nNous sommes : Des passionnés, investis dans l’épanouissement de nos chûnins (nos collaborateurs). Portés par une énergie collective et un véritable esprit de service, toujours prêts à relever les défis. Aussi agiles que des ninjas... ou presque. Aujourd’hui, pour l’un de nos clients de premier plan dans le secteur bancaire, engagé dans une transformation digitale de grande envergure, nous recherchons notre DATA INGENIEUR H/F. Si les projets à forte valeur ajoutée et l’innovation sont ton terrain de jeu, rejoins nous pour façonner l’avenir !\nTon objectif :\nEn tant que Data Ingénieur, tu seras amener à construire, maintenir et optimiser des systèmes et des infrastructures de gestion des données, en garantissant leur accessibilité, leur qualité et leur sécurité.\nTes principales missions :",
        "link": "https://www.glassdoor.fr/job-listing/data-engineer-hf-nind%C3%B4-group-JV_IC2881970_KO0,16_KE17,28.htm?jl=1009635225337"
    },
    {
        "title": "Project Manager Data Management - Financing & Risk (F/H)",
        "entreprise": "Natixis",
        "localisation": "Charenton",
        "contrat": "Non précisé",
        "description": "Institution financière internationale de premier plan, Natixis Corporate & Investment Banking met à disposition des entreprises, institutions financières, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking, financements, banque commerciale et sur les marchés de capitaux.\nSes équipes d'experts, présentes dans environ 30 pays, conseillent les clients sur leur développement stratégique en les accompagnant dans le développement et la transformation de leurs activités tout en maximisant leur impact positif. Natixis CIB s'engage sur un alignement de son portefeuille de financements sur une trajectoire de neutralité carbone d'ici 2050 tout en aidant ses clients à réduire l'impact environnemental de leur activité.\nNatixis CIB fait partie du pôle Global Financial Services du Groupe BPCE, deuxième groupe bancaire en France à travers les réseaux Banque Populaire et Caisse d'Epargne. Elle bénéficie de la puissance financière et des solides notations du Groupe (Standard & Poor's : A+, Moody's : A1, Fitch Ratings: A+, R&I : A+).",
        "link": "https://www.glassdoor.fr/job-listing/project-manager-data-management-financing-risk-fh-natixis-JV_IC3019638_KO0,49_KE50,57.htm?jl=1009618578364"
    },
    {
        "title": "Data Engineer H/F",
        "entreprise": "STUDIA",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "A propos de Studia\nLe Groupe STUDIA est spécialisé dans le management de contenu, l'ingénierie documentaire et la valorisation des données sensibles en temps réel.\nGrâce à l'expertise de ses 350 collaborateurs, STUDIA propose une offre complète et unique sur le marché qui s'articule autour de plusieurs expertises :\nLa gestion des contenus, des connaissances et des processus métiers\nLa valorisation de la donnée métier\nLa gestion de l'intégrité et de la sécurité de l'information\nLa transformation et la collaboration digitale\nL'industrie du futur et l'industrie 4.0.",
        "link": "https://www.glassdoor.fr/job-listing/data-engineer-hf-studia-JV_IC2881970_KO0,16_KE17,23.htm?jl=1009632902272"
    },
    {
        "title": "Head of Climate and Data Analytics in Germany (Darmstadt)",
        "entreprise": "EUMETSAT",
        "localisation": "France",
        "contrat": "Non précisé",
        "description": "EUMETSAT is an intergovernmental organisation based in Darmstadt, Germany. Our vision is to be the leading user-driven operational agency in Europe and a trusted global partner for weather and Earth system monitoring from space. All data provided by our state-of-the-art satellites systems are making a tangible difference in people's lives and contribute to the thriving European economy.\nEUMETSAT uses data from its growing fleet of earth observation satellites and from other agencies to support weather prediction in its Member States and worldwide. EUMETSAT also strongly supports climate monitoring by providing a wide range of satellite data, including rescued, recalibrated and reprocessed long time series of satellite observations. These time-series also increasingly serve as training datasets for machine learning in various application areas. As part of this, users are increasingly supported using machine learning methods, e.g. for the development of a characterisation of weather and climate-related features in the Earth system.",
        "link": "https://www.glassdoor.fr/job-listing/head-of-climate-and-data-analytics-in-germany-darmstadt-eumetsat-JV_KO0,55_KE56,64.htm?jl=1009572051860"
    },
    {
        "title": "Stage - Data Engineer - Mars 2025",
        "entreprise": "Sienna Investment Managers",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "Description de l'entreprise\n\nSienna IM - Listed Assets (Sienna Gestion) est une société de gestion agréée par l’AMF avec plus de 50 ans d’existence, et spécialisée dans l’investissement de long terme, avec un ADN marqué par l’investissement responsable.\nNous proposons des solutions d’investissement aux investisseurs institutionnels et privés sur l’ensemble des classes d’actifs (actions, taux, diversifiés, actifs réels) visant à favoriser l’investissement à impact environnemental et à impact social pour des investisseurs privés et institutionnels et disposons d’un encours de plus de 25 Mds€ à fin juin 2024.\nDotée d’une soixantaine de collaborateurs, Sienna IM - Listed Assets est issue du partenariat stratégique entre deux actionnaires : Sienna Investment Managers (Groupe Bruxelles Lambert), acteur européen spécialisé en gestion d’actifs non cotés (dette privée, private equity, venture capital, immobilier) et Malakoff Humanis, groupe mutualiste et paritaire, acteur de référence de la protection sociale en France.",
        "link": "https://www.glassdoor.fr/job-listing/stage-data-engineer-mars-2025-sienna-investment-managers-JV_IC2881970_KO0,29_KE30,56.htm?jl=1009646980702"
    },
    {
        "title": "Rédacteur Web – Apprentissage (f/h)",
        "entreprise": "Officéo",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "Tes missions & responsabilités\nNous recherchons un(e) Rédacteur(trice) Web en apprentissage, créatif(ve), centré(e) client et doté(e) de compétences marketing variées pour rejoindre notre équipe afin de développer notre stratégie et son exécution en matière de marketing de contenus.\nEn nous rejoignant, tu feras partie de l'équipe Marketing & Développement, composée d'un CMO, d’un Growth Engineer et de trois Content Creators.\nConcrètement, afin de soutenir nos efforts de génération de leads et de notoriété de marque, tu participeras notamment aux missions suivantes :\nEtude sémantique en analysant notamment les content gaps concurrentiels ;\nAnalyse des pages de résultats de recherche pour identifier les intentions de recherche, la qualité de l’information requise et les formats offrant des opportunités de positionnements (résultats enrichis, position 0…) ;\nOptimisation ou production de contenus textuels, visuels (infographies) ou vidéos répondant aux pratiques SEO post-HCU et en prévision de l’arrivée en France d’AI Overviews (pyramide inversée, EEAT) apportant une plus-value à l’intention de recherche et faisant subtilement migrer l’internaute dans notre entonnoir de conversion ;\nRecommandation et mise en place d’actions de SEO dit technique : structure de silo, maillage de nos cocons sémantiques selon la théorie du surfeur aléatoire raisonnable, balisage de données structurées ;\nNetlinking et échange de visibilité ;\nProduction de témoignages & cas clients ;\nAnimation communautaire sur nos réseaux sociaux & intranet assistants ;\nMise à jour de nos guides et templates.\nTon profil & tes compétences\nQui tu es :\nTu es en apprentissage ou à la recherche d’un stage, en fin de cycle diplômant (Bac+3 ou Bac+5), d’une école de communication, école de commerce ou école de journalisme ;\nTu as le sens de la formule et tu maîtrises l’art du storytelling dans un style concis et punchy qui apporte de la valeur à tes lecteurs ;\nCopywriter dans l’âme, tu aimes convaincre et générer de l’émotion à travers tes contenus, prouvé par des projets pro ou perso ;\nTu es créatif(ve) et te tiens au courant des dernières tendances en SEO, marketing de contenu, social media, marketing numérique ;\nTu possèdes une orthographe et syntaxe irréprochables ;\nDoté(e) d’un bon relationnel, tu es organisé(e), analytique, proactif(ve), et autonome.\nCe que cette expérience peut t'apporter :\nL'opportunité d'accélérer le déploiement de notre stratégie Lead Gen avec un gros potentiel ;\nL'opportunité de contribuer de façon concrète à une entreprise ambitieuse qui révolutionne un marché profond ;\nUn ownership & de l'autonomie sur tes sujets qui te permettra d'apprendre énormément et de construire quelque chose dont tu pourras être fier(e) ;\nUn environnement de travail stimulant, challengeant et bienveillant (point hebdomadaire en one-to-one pour sans cesse t'améliorer) ;\nL'opportunité de te perfectionner en SEO notamment via la maîtrise d’outils indispensables à ce canal permettant une analyse data-driven et une création de contenus augmentée par l’IA.\nNotre entreprise\nOfficéo (officeopro.com) est le leader français de l’externalisation administrative.\nNotre mission : Faire de l’Office Management un service agile, expert et fiable pour libérer toutes les organisations et favoriser la dynamique entrepreneuriale.\nN'embauchez, ni ne gérez plus de ressources humaines pour vos fonctions support.\nVia notre base d'Office Managers indépendants la plus large & la plus experte du marché, sublimée par notre technologie, vous faites changer d’échelle à vos services opérationnels.\nAvec Officéo, vous :\nLibérez du temps qualifié & productivisez vos B.U.\nMaîtrisez & variabilisez vos budgets\nSécurisez vos Business Process\nAlors si tu souhaites participer à l'aventure d'une entreprise à la fois rentable et en croissance et développer notamment notre stratégie d’acquisition Grands Comptes, rejoins-nous en tant que Rédacteur Web en apprentissage.\nDébut : Dès que possible\nProcess de recrutement\nEnvoi d’un CV et LM\nEchange téléphonique de 30 min\nEntretien de 2h avec Fabien (CMO) comprenant la réalisation d’un cas pratique\nEntretien de 30 min avec Patrick (CEO)\nType d'emploi : Alternance\nRémunération : 486,49€ à 1 405,40€ par mois\nAvantages :\nPrise en charge du transport quotidien\nHoraires :\nDu lundi au vendredi\nLieu du poste : En présentiel",
        "link": "https://www.glassdoor.fr/job-listing/r%C3%A9dacteur-web-apprentissage-fh-offic%C3%A9o-JV_IC2881970_KO0,30_KE31,38.htm?jl=1009633032018"
    },
    {
        "title": "Junior Data Engineer",
        "entreprise": "XL Catlin",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "Flexible Work Eligible: Remote Work\nDISCOVER your opportunity\n\nJunior Data Engineer – Business Intelligence\nLocation : Paris, Fr\nAXA XL offers risk transfer and risk management solutions to clients globally. We offer worldwide capacity, flexible underwriting solutions, a wide variety of client-focused loss prevention services and a team-based account management approach.\nAXA XL recognizes data and information as critical business assets, both in terms of managing risk and enabling new business opportunities. This data should not only be high quality, but also actionable – enabling AXA XL’sexecutive leadership team to maximize benefits and facilitate sustained competitive advantage. Our Chief Data Office also known as Innovation Data & Analytics (IDA) is focused on driving innovation through optimizing how we leverage data to drive strategy and create a new business model – disrupting the insurance market.",
        "link": "https://www.glassdoor.fr/job-listing/junior-data-engineer-xl-catlin-JV_IC2881970_KO0,20_KE21,30.htm?jl=1009591529863"
    },
    {
        "title": "Data Engineer Junior F/H",
        "entreprise": "Safran",
        "localisation": "Massy",
        "contrat": "Non précisé",
        "description": "Description du poste\nAu sein de la direction Achats SED, dans le pôle data du département Méthodes et outils, votre mission consiste à collecter, préparer, mettre en qualité, sécuriser et faire converger les données achats SED afin de les mettre à disposition des data analysts et data scientists et accompagner la transformation data des équipes.\n\nLes données de nos ERP sont actuellement analysées dans un datawarehouse BI Hana. Le groupe est en train de déployer une plateforme data AWS pour élargir les types et les possibilités d'exploitation de nos données. En collaboration étroite avec les équipes de la Direction informatique vous serez chargé de développer et maintenir l'infrastructure des données Achats SED sur AWS, d'optimiser et automatiser les flux de données du datawarehouse ou d'autres sources vers la plateforme, d'en assurer la qualité et la fiabilité et de mettre en place des bonnes pratiques en matière de gestion et de sécurité des données.\nA partir des besoins exprimés par le métier, vous collaborerez également avec les data analysts, les data scientists et les métiers pour comprendre leurs besoins et mettre à disposition des données exploitables dans le cadre de POC, de MVP ou de use case. Vous participerez à des ateliers afin d'identifier les données pertinentes, de les modéliser, de transformer, de mettre en qualité et de faire converger les données au sein de la plateforme data. Ponctuellement, vous serez également amené à concevoir et réaliser des analyses sous forme de reports\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBAC+5\nSupérieure à 3 ans",
        "link": "https://www.glassdoor.fr/job-listing/data-engineer-junior-fh-safran-JV_IC3040726_KO0,23_KE24,30.htm?jl=1009615317038"
    },
    {
        "title": "Data Engineer H/F - 2 ans d'expérience",
        "entreprise": "Chouette",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "Data Engineer (H/F)\nCDI - Paris 10e\nNotre ADN\nLancée en 2015, Chouette accompagne les agriculteurs pour les aider à mieux produire et maîtriser leurs coûts tout en diminuant l'impact environnemental de leurs cultures.\nGrâce à de l’acquisition continue depuis ses capteurs embarqués sur tracteurs et à ses algorithmes d’analyse d’images par intelligence artificielle, Chouette est capable de récolter et d’analyser un grand nombre de données pour permettre une meilleure gestion des exploitations agricoles (détection de maladies, analyse de rendement, recommandation de traitement de produits phytosanitaires, etc.).\nAfin de continuer son développement dans les meilleures conditions, Chouette a levé des fonds en 2023 dans le but d’enrichir ses services et de permettre une forte croissance de son activité dans les prochaines années.",
        "link": "https://www.glassdoor.fr/job-listing/data-engineer-hf2-ans-d-exp%C3%A9rience-chouette-JV_IC2881970_KO0,34_KE35,43.htm?jl=1009506940627"
    },
    {
        "title": "Consultant.e Data Engineer (H/F)",
        "entreprise": "groove",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "groove accompagne les organisations dans leur transformation numérique et durable ∞\nNotre mission :\nNous sommes profondément convaincus que l’économie numérique évolue vers une ère où la durabilité devient une priorité absolue.\nCe nouveau paradigme est au cœur de notre culture : une opportunité de bâtir un avenir en harmonie avec les enjeux écologiques, sociétaux et économiques. Notre équipe est animée par l’ambition de créer un impact positif, en adoptant une approche collaborative, éthique et tournée vers l’avenir.\nVotre rôle :\nEn tant que Consultant.e Data Engineer, vous accompagnez nos clients dans la conception, la mise en place et l’optimisation de leurs infrastructures de données. Vous intervenez à l’interface des enjeux techniques et stratégiques pour garantir la fiabilité, la performance et la scalabilité des pipelines de données, facilitant ainsi les analyses et la prise de décisions éclairées.",
        "link": "https://www.glassdoor.fr/job-listing/consultant-e-data-engineer-hf-groove-JV_IC2881970_KO0,29_KE30,36.htm?jl=1009620269332"
    },
    {
        "title": "Data Engineer",
        "entreprise": "MKG Qualiting",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "Data Engineer – B.I.\nNous recherchons un Data Engineer avec une expertise solide en SQL Server et Python pour construire des rapports en SSRS et Power BI. Ce poste exige une maîtrise approfondie des outils BI, de la modélisation des données et du développement de rapports.\nResponsabilités Clés :\n· Développer, concevoir et déployer des rapports SSRS basés sur des modèles Excel complexes existants.\n· Concevoir des requêtes, procédures stockées, fonctions scalaires ou tabulaires optimales, ainsi que des modèles de données pour garantir des performances optimales des rapports.\n· Valider l'exactitude et l'exhaustivité des livrables.\n· Documenter les processus de développement des rapports, les modèles de données et toute information pertinente.",
        "link": "https://www.glassdoor.fr/job-listing/data-engineer-mkg-qualiting-JV_IC2881970_KO0,13_KE14,27.htm?jl=1009527898644"
    },
    {
        "title": "STAGIAIRE DATA ENGINEER (LOB25-STA-08)",
        "entreprise": "Lobellia",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "A PROPOS\nVous interviendrez au sein d’une équipe constituée de 3 consultants expérimentés et d’un chef de projet. Vous prendrez en charge un périmètre de réalisation avec le développement et la qualification des développements en utilisant l’ETL TALEND pour les alimentations et la structuration des données issues de différents systèmes sources, complété de l’outil PowerBI pour la réalisation des tableaux de bord, des rapports et des dataset pour offrir des services de Self-BI. Cette mission vous permettra de développer des compétences sur l’architecture applicative d’une plateforme DATA moderne, la réalisation de procédures d’alimentation en utilisant un ETL et sur la mise en place de modules de reporting relationnel et multidimensionnel tout en faisant l’acquisition de connaissance sur la démarche de mise en œuvre d’un projet décisionnel.\nDESCRIPTIF DU POSTE",
        "link": "https://www.glassdoor.fr/job-listing/stagiaire-data-engineer-lob25-sta-08-lobellia-JV_IC2881970_KO0,36_KE37,45.htm?jl=1009465577061"
    },
    {
        "title": "Data Engineer GCP",
        "entreprise": "Sfeir",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "Qui sommes-nous ?\n\nSFEIR, partenaire Premier de Google Cloud, est une communauté de 900 experts Tech dont plus de 100 spécialistes Data.\n\nSFEIR c’est aussi\n\n140 certifiés sur GCP\n70 Trainers\n7 Google Developers Experts",
        "link": "https://www.glassdoor.fr/job-listing/data-engineer-gcp-sfeir-JV_IC2881970_KO0,17_KE18,23.htm?jl=1009644013239"
    },
    {
        "title": "Data Engineer TALEND",
        "entreprise": "Synopsia Ingénierie",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "SYNOPSIA est une société de Service et d’Ingénierie Informatique à taille humaine. Créée en 1999, elle accompagne depuis 20 ans ses clients dans la concrétisation de leurs projets numériques, en mettant à leur disposition une expertise technique et des compétences métier.\nChez SYNOPSIA nous avons à cœur d’avoir une réelle proximité avec chacun de nos salariés et nous œuvrons pour le développement de leur carrière en adéquation avec leur projet professionnel. A ce titre, nous attachons une grande importance au choix des missions et à la formation professionnelle. Nous recherchons des Hommes et des Femmes qui partagent nos valeurs : le sens du service, une ouverture d’esprit et une volonté de relever les défis qui se présentent à eux.\nNous recherchons activement un Data Engineer TALEND H/F pour une prise de poste rapide.\nVous intégrerez un projet pour lequel vous devrez relever les challenges d’aujourd’hui et de demain en intégrant les données au sein d’infrastructures, On-Premise et Cloud.",
        "link": "https://www.glassdoor.fr/job-listing/data-engineer-talend-synopsia-ing%C3%A9nierie-JV_IC2881970_KO0,20_KE21,40.htm?jl=1009032561961"
    },
    {
        "title": "Engineering Manager Socle Data",
        "entreprise": "AXA",
        "localisation": "Nanterre",
        "contrat": "Non précisé",
        "description": "Référence de l’offre\n24122955\nType de contrat\nCDI\nNiveau d'expérience\nExpérimentés\nSociété du groupeAXA France\nFamille métierIT, Data & Transformation\nLocalisation\nNANTERRE, Hauts-de-Seine",
        "link": "https://www.glassdoor.fr/job-listing/engineering-manager-socle-data-axa-JV_IC3019245_KO0,30_KE31,34.htm?jl=1009576541370"
    },
    {
        "title": "Analytics Engineer - Data Platform",
        "entreprise": "YOTTA",
        "localisation": "Paris",
        "contrat": "Non précisé",
        "description": "Analytics Engineer - Data Platform\n65K à 75K€\nParis, France\nCette société spécialisée en Data construit des Plateformes Data pour ses clients avec notamment une approche et des technologies Data modernes.\nElle accompagne notamment des clients sur la construction de leurs architectures et leurs plateformes data.\nEn forte croissance, elle recherche à consolider son équipe Data en recrutant un profil Analytics Engineer ayant une belle expérience et pouvant apporter son expertise sur la partie Data & Analytics.\nAu sein d’une équipe Data et rattaché directement au Directeur Data vous travaillerez sur la mise en place de Modern Data Stack et des architectures Data complexes.",
        "link": "https://www.glassdoor.fr/job-listing/analytics-engineer-data-platform-yotta-JV_IC2881970_KO0,32_KE33,38.htm?jl=1009635896701"
    }
]